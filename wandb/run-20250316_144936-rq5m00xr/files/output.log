training in progress...
starting new batching
tensor([[[0.2039, 0.2039, 0.2000,  ..., 0.2196, 0.2196, 0.2196],
         [0.2118, 0.2078, 0.2039,  ..., 0.2157, 0.2078, 0.2078],
         [0.2235, 0.2196, 0.2118,  ..., 0.2039, 0.1882, 0.1804],
         ...,
         [0.1804, 0.1843, 0.1882,  ..., 0.2627, 0.2588, 0.2549],
         [0.1804, 0.1843, 0.1843,  ..., 0.2510, 0.2549, 0.2588],
         [0.1804, 0.1804, 0.1804,  ..., 0.2431, 0.2549, 0.2588]]])
torch.Size([1, 128, 128])
Traceback (most recent call last):
  File "c:\Users\brand\OneDrive\Documents\CMPM17-ML\CMPM17-Final-HandSignRecognition\main.py", line 246, in <module>
    pred = model(images[i])
                 ~~~~~~^^^
IndexError: tensors used as indices must be long, int, byte or bool tensors
