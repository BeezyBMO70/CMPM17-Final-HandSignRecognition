training in progress...
starting new batching
tensor([[[0.1725, 0.1725, 0.1686,  ..., 0.1647, 0.1765, 0.1843],
         [0.1725, 0.1686, 0.1686,  ..., 0.1647, 0.1725, 0.1804],
         [0.1686, 0.1647, 0.1608,  ..., 0.1608, 0.1686, 0.1725],
         ...,
         [0.1686, 0.1725, 0.1765,  ..., 0.1961, 0.1882, 0.1843],
         [0.1569, 0.1608, 0.1725,  ..., 0.1961, 0.1686, 0.1569],
         [0.1490, 0.1569, 0.1725,  ..., 0.1961, 0.1608, 0.1451]]])
torch.Size([1, 128, 128])
Traceback (most recent call last):
  File "c:\Users\brand\OneDrive\Documents\CMPM17-ML\CMPM17-Final-HandSignRecognition\main.py", line 247, in <module>
    pred = model(i)
           ^^^^^^^^
  File "C:\Users\brand\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brand\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\brand\OneDrive\Documents\CMPM17-ML\CMPM17-Final-HandSignRecognition\main.py", line 178, in forward
    partial = self.linearlayer1(partial)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brand\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brand\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\brand\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mat1 and mat2 shapes cannot be multiplied (100x256 and 25600x4096)
